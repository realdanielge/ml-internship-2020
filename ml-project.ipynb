{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated 3/22/2022\n",
    "#Import modules\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that prints progress bar while running tests.\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.00265128, -0.00155958, ...,  0.00467873,\n",
       "         0.00904554,  0.00483468],\n",
       "       [ 0.        , -0.00837859, -0.00853375, ...,  0.00232739,\n",
       "        -0.0007758 ,  0.00062064],\n",
       "       [ 0.        ,  0.01818462,  0.01941748, ...,  0.02327015,\n",
       "         0.02619818,  0.028818  ],\n",
       "       ...,\n",
       "       [ 0.        , -0.00344097, -0.00605006, ..., -0.0082054 ,\n",
       "        -0.00461317, -0.00434848],\n",
       "       [ 0.        ,  0.00437362,  0.00182551, ...,  0.00079866,\n",
       "         0.00193961,  0.00258614],\n",
       "       [ 0.        ,  0.00154309,  0.00255928, ...,  0.00109146,\n",
       "        -0.00015055,  0.00045164]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and scale raw S&P 500 data.\n",
    "\n",
    "path = \"datasets/\"\n",
    "spy_df = pd.read_csv(path + 'spy_30min_pi_clean.csv')\n",
    "\n",
    "spy_df[\"Date\"] = pd.to_datetime(spy_df[\"Date\"])\n",
    "\n",
    "#Pivot the data such that vertical axis is date, horizontal axis is time of day.\n",
    "pivot_spy_df = spy_df.copy()\n",
    "pivot_spy_df = spy_df.pivot(index = \"Time\", columns = \"Date\", values = \"Close\")\n",
    "\n",
    "spy_np = pivot_spy_df.to_numpy().T\n",
    "\n",
    "\"\"\"\n",
    "Different Methods for Scaling Data (in numpy arrays)\n",
    "\"\"\"\n",
    "#Scale by percent change since previous day's market close.\n",
    "def scale_by_pcspc(np_array):\n",
    "    scaled_np_array = np_array.copy()\n",
    "    #Special case: Divide the first day of dataset by its opening price.\n",
    "    scaled_np_array[0] = (scaled_np_array[0] - np_array[0][0])/np_array[0][0]\n",
    "    for i in range(1, len(np_array)):\n",
    "        #Find previous day's market close.\n",
    "        prev_close = np_array[i-1][12]\n",
    "        #Find percent change since previous day's market close.\n",
    "        scaled_np_array[i] = (scaled_np_array[i] - prev_close)/prev_close\n",
    "    return scaled_np_array\n",
    "\n",
    "#Scale by percent change since market open.\n",
    "def scale_by_pcsmo(np_array):\n",
    "    scaled_np_array = np_array.copy()\n",
    "    for i in range(len(np_array)):\n",
    "        #Find percent change since market open.\n",
    "        scaled_np_array[i] = (scaled_np_array[i] - np_array[i][0])/np_array[i][0]\n",
    "    return scaled_np_array\n",
    "\n",
    "#Standardize by each day's input prices.\n",
    "def standardize_by_daily(np_array, start, end):\n",
    "    scaled_np_array = np_array.copy()\n",
    "    for i in range(len(np_array)):\n",
    "        #Find the day's mean and standard deviation.\n",
    "        daily_mean = np.mean(np_array[i][start:end])\n",
    "        daily_std = np.std(np_array[i][start:end])\n",
    "        #Standardize via mean and standard deviation.\n",
    "        scaled_np_array[i] = (scaled_np_array[i] - daily_mean)/daily_std\n",
    "    return scaled_np_array\n",
    "\n",
    "#Normalize by historical min and max prices.\n",
    "def normalize_by_hist(np_array):\n",
    "    scaled_np_array = np_array.copy()\n",
    "    #Find the historical min and max prices throughout the whole dataset.\n",
    "    hist_min = np.min(np_array)\n",
    "    hist_max = np.max(np_array)\n",
    "    for i in range(len(np_array)):\n",
    "        #Normalize via historical min and max prices.\n",
    "        scaled_np_array[i] = (scaled_np_array[i] - hist_min)/(hist_max - hist_min)\n",
    "    return scaled_np_array\n",
    "\n",
    "#Standardize by mean and std of historical prices.\n",
    "def standardize_by_hist(np_array):\n",
    "    scaled_np_array = np_array.copy()\n",
    "    #Find the mean and std of historical prices\n",
    "    hist_mean = np.mean(np_array)\n",
    "    hist_std = np.std(np_array)\n",
    "    for i in range(len(np_array)):\n",
    "        #Standardize via mean and std of historical prices.\n",
    "        scaled_np_array[i] = (scaled_np_array[i] - hist_mean)/(hist_std)\n",
    "    return scaled_np_array\n",
    "\n",
    "scaled_spy_np = scale_by_pcsmo(spy_np)\n",
    "\n",
    "scaled_spy_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Date</th>\n",
       "      <th>2002-12-30</th>\n",
       "      <th>2002-12-31</th>\n",
       "      <th>2003-01-02</th>\n",
       "      <th>2003-01-03</th>\n",
       "      <th>2003-01-06</th>\n",
       "      <th>2003-01-07</th>\n",
       "      <th>2003-01-08</th>\n",
       "      <th>2003-01-09</th>\n",
       "      <th>2003-01-10</th>\n",
       "      <th>2003-01-13</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-01-11</th>\n",
       "      <th>2019-01-14</th>\n",
       "      <th>2019-01-15</th>\n",
       "      <th>2019-01-16</th>\n",
       "      <th>2019-01-17</th>\n",
       "      <th>2019-01-18</th>\n",
       "      <th>2019-01-22</th>\n",
       "      <th>2019-01-23</th>\n",
       "      <th>2019-01-24</th>\n",
       "      <th>2019-01-25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10:00:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10:30:00</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11:00:00</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11:30:00</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12:00:00</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12:30:00</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:00:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:30:00</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14:00:00</th>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14:30:00</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15:00:00</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15:30:00</th>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16:00:00</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows Ã— 4007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Date      2002-12-30  2002-12-31  2003-01-02  2003-01-03  2003-01-06  \\\n",
       "Time                                                                   \n",
       "10:00:00       0.000       0.000       0.000       0.000       0.000   \n",
       "10:30:00       0.003      -0.008       0.018      -0.001       0.004   \n",
       "11:00:00      -0.002      -0.009       0.019      -0.002       0.006   \n",
       "11:30:00      -0.002      -0.006       0.018      -0.002       0.007   \n",
       "12:00:00      -0.001      -0.004       0.020      -0.002       0.008   \n",
       "12:30:00       0.001      -0.002       0.020      -0.003       0.008   \n",
       "13:00:00       0.000      -0.001       0.022      -0.002       0.010   \n",
       "13:30:00       0.003       0.002       0.021      -0.001       0.012   \n",
       "14:00:00       0.004      -0.001       0.021       0.000       0.011   \n",
       "14:30:00       0.003       0.002       0.024      -0.003       0.014   \n",
       "15:00:00       0.005       0.002       0.023      -0.004       0.016   \n",
       "15:30:00       0.009      -0.001       0.026      -0.000       0.016   \n",
       "16:00:00       0.005       0.001       0.029       0.002       0.013   \n",
       "\n",
       "Date      2003-01-07  2003-01-08  2003-01-09  2003-01-10  2003-01-13  ...  \\\n",
       "Time                                                                  ...   \n",
       "10:00:00       0.000       0.000       0.000       0.000       0.000  ...   \n",
       "10:30:00      -0.001       0.003       0.005       0.004      -0.007  ...   \n",
       "11:00:00      -0.005       0.001       0.007       0.008      -0.011  ...   \n",
       "11:30:00      -0.001       0.005       0.007       0.004      -0.009  ...   \n",
       "12:00:00       0.001       0.002       0.007       0.007      -0.008  ...   \n",
       "12:30:00      -0.000      -0.001       0.006       0.002      -0.007  ...   \n",
       "13:00:00      -0.002      -0.001       0.005       0.000      -0.007  ...   \n",
       "13:30:00       0.000      -0.001       0.004       0.000      -0.009  ...   \n",
       "14:00:00       0.003      -0.003       0.002       0.002      -0.007  ...   \n",
       "14:30:00       0.001      -0.003       0.004       0.003      -0.006  ...   \n",
       "15:00:00      -0.001      -0.006       0.005       0.005      -0.008  ...   \n",
       "15:30:00      -0.002      -0.006       0.005       0.002      -0.008  ...   \n",
       "16:00:00      -0.003      -0.006       0.007       0.004      -0.009  ...   \n",
       "\n",
       "Date      2019-01-11  2019-01-14  2019-01-15  2019-01-16  2019-01-17  \\\n",
       "Time                                                                   \n",
       "10:00:00       0.000       0.000       0.000       0.000       0.000   \n",
       "10:30:00      -0.001       0.001      -0.001      -0.000       0.000   \n",
       "11:00:00       0.002       0.003       0.002      -0.001       0.000   \n",
       "11:30:00       0.002       0.001       0.001       0.000       0.002   \n",
       "12:00:00       0.003       0.002       0.004      -0.002       0.002   \n",
       "12:30:00       0.004       0.003       0.005      -0.001       0.002   \n",
       "13:00:00       0.005       0.003       0.004      -0.000       0.001   \n",
       "13:30:00       0.002       0.003       0.004      -0.000       0.003   \n",
       "14:00:00       0.003       0.003       0.004      -0.000       0.003   \n",
       "14:30:00       0.004       0.002      -0.000       0.001       0.002   \n",
       "15:00:00       0.003       0.004       0.002       0.000       0.006   \n",
       "15:30:00       0.003       0.003       0.003       0.001       0.006   \n",
       "16:00:00       0.005       0.001       0.005      -0.002       0.007   \n",
       "\n",
       "Date      2019-01-18  2019-01-22  2019-01-23  2019-01-24  2019-01-25  \n",
       "Time                                                                  \n",
       "10:00:00       0.000       0.000       0.000       0.000       0.000  \n",
       "10:30:00       0.001      -0.001      -0.003       0.004       0.002  \n",
       "11:00:00       0.004      -0.002      -0.006       0.002       0.003  \n",
       "11:30:00       0.006      -0.002      -0.008       0.001       0.001  \n",
       "12:00:00       0.007      -0.006      -0.012       0.003       0.002  \n",
       "12:30:00       0.009      -0.006      -0.011       0.001       0.003  \n",
       "13:00:00       0.008      -0.005      -0.009      -0.000       0.001  \n",
       "13:30:00       0.007      -0.008      -0.009      -0.002       0.002  \n",
       "14:00:00       0.007      -0.007      -0.008      -0.001       0.002  \n",
       "14:30:00       0.005      -0.010      -0.006      -0.000      -0.000  \n",
       "15:00:00       0.006      -0.010      -0.008       0.001       0.001  \n",
       "15:30:00       0.006      -0.009      -0.005       0.002      -0.000  \n",
       "16:00:00       0.007      -0.006      -0.004       0.003       0.000  \n",
       "\n",
       "[13 rows x 4007 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_spy_df = pivot_spy_df\n",
    "\n",
    "for col in scaled_spy_df.columns:\n",
    "    start_close = scaled_spy_df[col].iloc[0]\n",
    "    min_close = scaled_spy_df[col].min()\n",
    "    max_close = scaled_spy_df[col].max()\n",
    "    #Scale by percent change\n",
    "    scaled_spy_df[col] = scaled_spy_df[col].apply(lambda x : (x-start_close)/(start_close))\n",
    "    #Round to 3 decimal places.\n",
    "    scaled_spy_df[col] = scaled_spy_df[col].apply(lambda x : round(x,3))\n",
    "\n",
    "#scaled_spy_df.dropna(axis=1, inplace = True)\n",
    "\n",
    "scaled_spy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_spy_np has length 13\n",
      "X has length 9 \n",
      "y has length 4\n"
     ]
    }
   ],
   "source": [
    "#Split data into input and output.\n",
    "X = scaled_spy_np[:,0:9] #Input: Prices from 10:00:00 to 14:00:00\n",
    "y = scaled_spy_np[:,9:13] #Output: Prices from 14:30:00 to 16:00:00 (What we are predicting)\n",
    "\n",
    "#Print the dimensions of the input and output data.\n",
    "print(\"scaled_spy_np has length {}\".format(len(scaled_spy_np[0])))\n",
    "print(\"X has length {} \\ny has length {}\".format(len(X[0]), len(y[0])))\n",
    "\n",
    "#Split data into training and testing data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a neural network model.\n",
    "\n",
    "def create_model(input_dim, output_dim, hidden_layers, learning_rate, activation, loss):\n",
    "    #Create the model\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    #Add hidden layers\n",
    "    for i in range(len(hidden_layers)):\n",
    "        if i==0:\n",
    "            model.add(tf.keras.layers.Dense(units=hidden_layers[i], activation=activation, input_dim = input_dim))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Dense(units=hidden_layers[i], activation=activation))\n",
    "\n",
    "    #Add output layer\n",
    "    model.add(tf.keras.layers.Dense(units=output_dim))\n",
    "\n",
    "    #Create the optimizer\n",
    "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate a model multiple times and displays average performance.\n",
    "@params\n",
    "    model: The model to be evaluated.\n",
    "    X: The input data\n",
    "    y: The output data\n",
    "    k_folds: Number of folds to use in cross validation.\n",
    "\"\"\"\n",
    "\n",
    "def test_model(model, epochs, X, y, k_folds, **kwargs):\n",
    "    test_losses = []\n",
    "    \n",
    "    #Print progress bar\n",
    "    if(kwargs.get('verbose') == 1):\n",
    "        printProgressBar(0, k_folds, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "    \n",
    "    #Shuffle X and y\n",
    "    np.random.shuffle(X)\n",
    "    np.random.shuffle(y)\n",
    "\n",
    "    #Split data into k folds for cross validation.\n",
    "    kf = KFold(n_splits=k_folds)\n",
    "    kf.get_n_splits(X)\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        #Fit the model\n",
    "        model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "        \n",
    "        #Evalaute the model and store the test loss.\n",
    "        test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        #Store the performance data\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        #Update progress bar\n",
    "        if(kwargs.get('verbose') == 1):\n",
    "            printProgressBar(i + 1, k_folds, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "            i += 1\n",
    "    \n",
    "    #Average the performance data across every fold.\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    return avg_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Average test loss: 0.005020525585860014\n"
     ]
    }
   ],
   "source": [
    "#Create model with 2x32 hidden layers, 0.001 learning rate, ReLu actiation function, and mean average error as loss function.\n",
    "model = create_model(input_dim=9, hidden_layers=[32,32], output_dim=4, learning_rate=0.001, activation='relu',  \n",
    "                     loss='mae')\n",
    "\n",
    "#Test model and store the average test loss\n",
    "avg_test_loss = test_model(model, 30, X, y, k_folds=10, verbose=1)\n",
    "\n",
    "#Print average test loss\n",
    "print(\"Average test loss: {}\".format(avg_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Learning Rate 0.0001 achieved test loss of 0.004993808083236217\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Learning Rate 0.0005 achieved test loss of 0.004987978003919124\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Learning Rate 0.001 achieved test loss of 0.00497784917242825\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Learning Rate 0.005 achieved test loss of 0.005065590282902122\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Learning Rate 0.01 achieved test loss of 0.005232418375089765\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Learning Rate 0.05 achieved test loss of 0.15582910869270564\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Learning Rate 0.1 achieved test loss of 0.2611540764570236\n"
     ]
    }
   ],
   "source": [
    "#Optimize learning rate\n",
    "\n",
    "#Array containing learning rates to test\n",
    "learning_rates = np.array([0.0001,0.0005,0.001,0.005,0.01,0.05,0.1])\n",
    "avg_test_losses = []\n",
    "\n",
    "#Create and test a model with every learning rate.\n",
    "for learning_rate in learning_rates:\n",
    "    #Create model\n",
    "    model = create_model(input_dim=9, hidden_layers=[32,32], output_dim=4, learning_rate=learning_rate, activation='tanh',  \n",
    "                     loss='mae')\n",
    "    \n",
    "    #Find average test loss\n",
    "    avg_test_loss = test_model(model, 30, X, y, k_folds=10, verbose=1)\n",
    "    \n",
    "    #Print test loss for each learning rate\n",
    "    print(\"Learning Rate {} achieved test loss of {}\".format(learning_rate, avg_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Epoch 2 achieved test loss of 0.005035998485982418\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Epoch 4 achieved test loss of 0.005006768787279725\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Epoch 8 achieved test loss of 0.0050131228752434255\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Epoch 16 achieved test loss of 0.0049853658769279715\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Epoch 32 achieved test loss of 0.004992210166528821\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Epoch 64 achieved test loss of 0.0050052586942911145\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Epoch 128 achieved test loss of 0.004989310633391142\n"
     ]
    }
   ],
   "source": [
    "#Optimize Epochs\n",
    "\n",
    "#Array containing number of epochs to test\n",
    "epochs = [2,4,8,16,32, 64, 128]\n",
    "avg_test_losses = []\n",
    "\n",
    "#Create and test a model with every number of epochs.\n",
    "for epoch in epochs:\n",
    "    #Create model\n",
    "    model = create_model(input_dim=9, hidden_layers=[32,32], output_dim=4, learning_rate=0.001, activation='tanh',  \n",
    "                     loss='mae')\n",
    "    \n",
    "    #Find average test loss\n",
    "    avg_test_loss = test_model(model, epoch, X, y, k_folds=10, verbose=1)\n",
    "    \n",
    "    #Print test loss for each epoch\n",
    "    print(\"Epoch {} achieved test loss of {}\".format(epoch, avg_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Num hidden layers of 2 achieved test loss of 0.005023041693493724\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Num hidden layers of 4 achieved test loss of 0.0050401970278471705\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Num hidden layers of 8 achieved test loss of 0.0049889445770531895\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Num hidden layers of 16 achieved test loss of 0.005018215253949165\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Num hidden layers of 32 achieved test loss of 0.005006318911910057\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Num hidden layers of 64 achieved test loss of 0.005006772186607123\n"
     ]
    }
   ],
   "source": [
    "#Optimize Number of Hidden Layers\n",
    "\n",
    "#Array containing number of hidden layers to test\n",
    "num_hidden_layers = [2,4,8,16,32,64]\n",
    "avg_test_losses = []\n",
    "\n",
    "#Create and test a model with every number of hidden layers.\n",
    "for num in num_hidden_layers:\n",
    "    #Create model\n",
    "    model = create_model(input_dim=9, hidden_layers=[32]*num, output_dim=4, learning_rate=0.001, activation='tanh',  \n",
    "                     loss='mae')\n",
    "    \n",
    "    #Find average test loss.\n",
    "    avg_test_loss = test_model(model, 30, X, y, k_folds=10, verbose=1)\n",
    "    \n",
    "    #Print test loss for each number of hidden layers\n",
    "    print(\"Num hidden layers of {} achieved test loss of {}\".format(num, avg_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Hidden layer size 2 achieved test loss of 0.005024055717512965\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Hidden layer size 4 achieved test loss of 0.004986590845510364\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Hidden layer size 8 achieved test loss of 0.004993353085592389\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Hidden layer size 16 achieved test loss of 0.005004382180050016\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Hidden layer size 32 achieved test loss of 0.005000432068482041\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Hidden layer size 64 achieved test loss of 0.005024759937077761\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Hidden layer size 128 achieved test loss of 0.005001226114109159\n"
     ]
    }
   ],
   "source": [
    "#Optimize Hidden Layer Size\n",
    "\n",
    "#Array containing hidden layer sizes to test\n",
    "hidden_layer_sizes = [2,4,8,16,32,64,128]\n",
    "avg_test_losses = []\n",
    "\n",
    "#Create and test a model with every hidden layer size.\n",
    "for size in hidden_layer_sizes:\n",
    "    #Create model\n",
    "    model = create_model(input_dim=9, hidden_layers=[size]*2, output_dim=4, learning_rate=0.001, activation='tanh',  \n",
    "                     loss='mae')\n",
    "    \n",
    "    #Find average test loss\n",
    "    avg_test_loss = test_model(model, 30, X, y, k_folds=10, verbose=1)\n",
    "    \n",
    "    #Print test loss for each hidden layer size\n",
    "    print(\"Hidden layer size {} achieved test loss of {}\".format(size, avg_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Activation tanh achieved test loss of 0.004989201761782169\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Activation relu achieved test loss of 0.005007611168548465\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Activation sigmoid achieved test loss of 0.00557960569858551\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Activation softmax achieved test loss of 0.005043719569221139\n"
     ]
    }
   ],
   "source": [
    "#Optimize Activation Function\n",
    "\n",
    "#Array containing activation functions to test\n",
    "activations = ['tanh', 'relu', 'sigmoid', 'softmax']\n",
    "\n",
    "#Create and test a model with activation function.\n",
    "for activation in activations:\n",
    "    #Create model\n",
    "    model = create_model(input_dim=9, hidden_layers=[32,32], output_dim=4, learning_rate=0.001, activation=activation,  \n",
    "                     loss='mae')\n",
    "    \n",
    "    #Find average test loss\n",
    "    avg_test_loss = test_model(model, 30, X, y, k_folds=10, verbose=1)\n",
    "    \n",
    "    #Print test loss for each activation function\n",
    "    print(\"Activation {} achieved test loss of {}\".format(activation, avg_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete\n",
      "Final model achieved test loss of 0.004994870815426111\n"
     ]
    }
   ],
   "source": [
    "#Test Optimized Model\n",
    "\n",
    "#Create an optimized model using the hyperparameters with the lowest test losses.\n",
    "model = create_model(input_dim=9, hidden_layers=[16]*8, output_dim=4, learning_rate=0.0005, activation='softmax',  \n",
    "                     loss='mae')\n",
    "\n",
    "#Find average test loss of optimized model\n",
    "avg_test_loss = test_model(model, 32, X, y, k_folds=10, verbose=1)\n",
    "\n",
    "#Print test loss for optimized model\n",
    "print(\"Final model achieved test loss of {}\".format(avg_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
